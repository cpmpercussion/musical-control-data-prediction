{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deterministic RNN Predictor\n",
    "\n",
    "Build and run deterministic RNN. Given the same input the model always predicts the same output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import absolute_import\n",
    "# from __future__ import division\n",
    "# from __future__ import print_function\n",
    "import keras\n",
    "# little path hack to get robojam from one directory up in the filesystem.\n",
    "from context import * # imports robojam\n",
    "# import robojam # alternatively do this.\n",
    "import h5py\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "input_colour = 'darkblue'\n",
    "gen_colour = 'firebrick'\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_df_to_array(perf_df):\n",
    "    \"\"\"Converts a dataframe of a performance into array a,b,dt format.\"\"\"\n",
    "    perf_df['dt'] = perf_df.time.diff()\n",
    "    perf_df.dt = perf_df.dt.fillna(0.0)\n",
    "    # Clean performance data\n",
    "    # Tiny Performance bounds defined to be in [[0,1],[0,1]], edit to fix this.\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 5].index, 'dt', 5.0)\n",
    "    perf_df.set_value(perf_df[perf_df.dt < 0].index, 'dt', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.x > 1].index, 'x', 1.0)\n",
    "    perf_df.set_value(perf_df[perf_df.x < 0].index, 'x', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.y > 1].index, 'y', 1.0)\n",
    "    perf_df.set_value(perf_df[perf_df.y < 0].index, 'y', 0.0)\n",
    "    return np.array(perf_df[['x', 'y', 'dt']])\n",
    "\n",
    "\n",
    "def perf_array_to_df(perf_array):\n",
    "    \"\"\"Converts an array of a performance (a,b,dt format) into a dataframe.\"\"\"\n",
    "    perf_array = perf_array.T\n",
    "    perf_df = pd.DataFrame({'x': perf_array[0], 'y': perf_array[1], 'dt': perf_array[2]})\n",
    "    perf_df['time'] = perf_df.dt.cumsum()\n",
    "    perf_df['z'] = 38.0\n",
    "    # As a rule of thumb, could classify taps with dt>0.1 as taps, dt<0.1 as moving touches.\n",
    "    perf_df['moving'] = 1\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 0.1].index, 'moving', 0)\n",
    "    perf_df = perf_df.set_index(['time'])\n",
    "    return perf_df[['x', 'y', 'z', 'moving']]\n",
    "\n",
    "\n",
    "def random_touch():\n",
    "    \"\"\"Generate a random tiny performance touch.\"\"\"\n",
    "    return np.array([np.random.rand(), np.random.rand(), 0.01])\n",
    "\n",
    "\n",
    "def constrain_touch(touch):\n",
    "    \"\"\"Constrain touch values from the MDRNN\"\"\"\n",
    "    touch[0] = min(max(touch[0], 0.0), 1.0)  # x in [0,1]\n",
    "    touch[1] = min(max(touch[1], 0.0), 1.0)  # y in [0,1]\n",
    "    touch[2] = max(touch[2], 0.001)  # dt # define minimum time step\n",
    "    return touch\n",
    "\n",
    "def generate_random_tiny_performance(model, first_touch, time_limit=5.0, steps_limit=1000, temp=1.0, model_file=None):\n",
    "    \"\"\"Generates a tiny performance up to 5 seconds in length.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    previous_touch = first_touch\n",
    "    performance = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        previous_touch = model.predict(previous_touch.reshape(1,1,3))\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        performance.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    return np.array(performance)\n",
    "\n",
    "\n",
    "def condition_and_generate(model, perf, time_limit=5.0, steps_limit=1000, temp=1.0, model_file=None):\n",
    "    \"\"\"Conditions the network on an existing tiny performance, then generates a new one.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    # condition\n",
    "    for touch in perf:\n",
    "        previous_touch = model.predict(touch.reshape(1,1,3))\n",
    "    output = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        previous_touch = model.predict(previous_touch.reshape(1,1,3))\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        output.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    net_output = np.array(output)\n",
    "    return net_output\n",
    "\n",
    "def divide_performance_into_swipes(perf_df):\n",
    "    \"\"\"Divides a performance into a sequence of swipe dataframes for plotting.\"\"\"\n",
    "    touch_starts = perf_df[perf_df.moving == 0].index\n",
    "    performance_swipes = []\n",
    "    remainder = perf_df\n",
    "    for att in touch_starts:\n",
    "        swipe = remainder.iloc[remainder.index < att]\n",
    "        performance_swipes.append(swipe)\n",
    "        remainder = remainder.iloc[remainder.index >= att]\n",
    "    performance_swipes.append(remainder)\n",
    "    return performance_swipes\n",
    "\n",
    "def plot_2D(perf_df, name=\"foo\", saving=False, xylim=1.0):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    swipes = divide_performance_into_swipes(perf_df)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(xylim,0)\n",
    "    plt.xlim(0,xylim)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def plot_double_2d(perf1, perf2, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot two performances in 2D\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    swipes = divide_performance_into_swipes(perf1)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=input_colour, linewidth=5.0)\n",
    "    swipes = divide_performance_into_swipes(perf2)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 30\n",
    "BATCH_SIZE = 256\n",
    "HIDDEN_UNITS = 64\n",
    "EPOCHS = 30\n",
    "VAL_SPLIT=0.2\n",
    "# These settings train for 2.1 epochs which is pretty good!\n",
    "SEED = 2345  # 2345 seems to be good.\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "# tf.set_random_seed(5791)  # only works for current graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "microjam_data_file_name = \"../datasets/TinyPerformanceCorpus.h5\"\n",
    "metatone_data_file_name = \"../datasets/MetatoneTinyPerformanceRecords.h5\"\n",
    "\n",
    "with h5py.File(microjam_data_file_name, 'r') as data_file:\n",
    "    microjam_corpus = data_file['total_performances'][:]\n",
    "with h5py.File(metatone_data_file_name, 'r') as data_file:\n",
    "    metatone_corpus = data_file['total_performances'][:]\n",
    "\n",
    "# Microjam Data\n",
    "# sequence_loader = robojam.sample_data.SequenceDataLoader(num_steps=SEQ_LEN + 1, batch_size=BATCH_SIZE, corpus=microjam_corpus, overlap=False)\n",
    "\n",
    "# Charles' PhD 'Metatone' dataset\n",
    "sequence_loader = robojam.sample_data.SequenceDataLoader(num_steps=SEQ_LEN + 1, batch_size=BATCH_SIZE, corpus=metatone_corpus, overlap=False)\n",
    "\n",
    "X, y = sequence_loader.seq_to_singleton_format()\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)\n",
    "\n",
    "# sklearn splits below are not used..\n",
    "import sklearn.model_selection\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "print(\"Train X:\", X_train.shape, \"y:\", y_train.shape)\n",
    "print(\"Test X:\", X_test.shape, \"y:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Sequential()\n",
    "encoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(None,SEQ_LEN,3), return_sequences=True))\n",
    "encoder.add(keras.layers.LSTM(HIDDEN_UNITS))\n",
    "encoder.add(keras.layers.Dense(3, activation='relu'))\n",
    "encoder.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"gesture-RNN\" style network.\n",
    "encoder = keras.Sequential()\n",
    "encoder.add(keras.layers.LSTM(64, batch_input_shape=(None,SEQ_LEN,3), return_sequences=True))\n",
    "encoder.add(keras.layers.LSTM(32))\n",
    "encoder.add(keras.layers.Dense(16, activation='relu'))\n",
    "encoder.add(keras.layers.Dense(3, activation='relu'))\n",
    "encoder.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = encoder.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=VAL_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renamed from 'baseline_RNN_predictor' to 'deterministic_RNN_predictor'\n",
    "encoder.save(\"deterministic_RNN_predictor.h5\")\n",
    "# Good MSE error would be 0.004\n",
    "# Right now (30 epochs) training: 0.0177, validation: 0.0204\n",
    "# 100 epochs training: 0.0109, validation: 0.0230. no improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load from saved.\n",
    "from keras.models import load_model\n",
    "encoder = load_model(\"deterministic_RNN_predictor.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = keras.Sequential()\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(1,1,3), return_sequences=True, stateful=True))\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, stateful=True))\n",
    "decoder.add(keras.layers.Dense(3, activation='relu'))\n",
    "decoder.compile(loss='mse', optimizer=keras.optimizers.Adam())\n",
    "decoder.summary()\n",
    "\n",
    "\n",
    "decoder.set_weights(encoder.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "\n",
    "Trying out the model with some different kinds of input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test just generating single performances.\n",
    "\n",
    "p = generate_random_tiny_performance(decoder, random_touch()) #, time_limit=60.0, steps_limit=10000) \n",
    "plot_2D(perf_array_to_df(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_2D(perf_array_to_df(sequence_loader.examples[512]))\n",
    "t = random.randint(0,len(sequence_loader.examples))\n",
    "t = random.randint(0,len(X_test))\n",
    "\n",
    "p = condition_and_generate(decoder,sequence_loader.examples[t])\n",
    "plot_double_2d(perf_array_to_df(sequence_loader.examples[t]), perf_array_to_df(p))\n",
    "decoder.reset_states()\n",
    "# plot_double_2d(in_df, out_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Maker Function\n",
    "\n",
    "A function that generates a Keras RNN model based on hyperparameters. This is the `charRNN` version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(model, layer_size=64, dropout_rate=0.5, num_layers=1, vocab_size=20, input_length=1, lr=0.01, train_mode=True):\n",
    "    \"\"\"Builds a charRNN model with variable layer size, number of layers, droupout, learning rate, and a training mode.\"\"\"\n",
    "    if train_mode:\n",
    "        stateful = False\n",
    "        input_shape = (None, input_length)\n",
    "    else:\n",
    "        stateful = True\n",
    "        input_shape = (1, input_length)\n",
    "    \n",
    "    # Input embedding\n",
    "    model.add(Embedding(vocab_size, layer_size, input_length=input_length, batch_input_shape=input_shape))\n",
    "              \n",
    "    # LSTM layers + 1\n",
    "    for i in range(num_layers - 1):\n",
    "        model.add(Dropout(dropout_rate))\n",
    "        model.add(LSTM(layer_size, return_sequences=True, stateful=stateful))\n",
    "    \n",
    "    # Final LSTM layer\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(LSTM(layer_size, stateful=stateful))\n",
    "\n",
    "    # Project back to vocabulary\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=lr))\n",
    "    model.summary()\n",
    "\n",
    "# m = Sequential()\n",
    "# model_maker(m, layer_size=128, vocab_size=vocabulary_size, input_length=30, train_mode=True)\n",
    "# m.fit(X, y, batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
