{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "import mdn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# # Only for GPU use:\n",
    "# import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "# import tensorflow as tf\n",
    "# config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "# sess = tf.Session(config=config)\n",
    "# from keras import backend as K\n",
    "# K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and process raw OSC saved data\n",
    "data = pd.read_csv(\"../datasets/2018-06-21-block-perf1.txt\")\n",
    "data['dt'] = data.time.diff().fillna(0)\n",
    "data['x'] = data.message.apply((lambda x: int(x.split(' ')[2]))) / 127.0\n",
    "data['dx'] = data.x.diff().fillna(0)\n",
    "data['y'] = data.message.apply((lambda x: int(x.split(' ')[3]))) / 127.0\n",
    "data['dy'] = data.y.diff().fillna(0)\n",
    "data['z'] = data.message.apply((lambda x: int(x.split(' ')[4]))) / 127.0\n",
    "data['dz'] = data.z.diff().fillna(0)\n",
    "\n",
    "# Save as numpy array\n",
    "cleaned_data = data[['dx', 'dy', 'dz', 'dt']]\n",
    "array_version = np.array(cleaned_data)\n",
    "np.savez('roli-block-session-data-diff.npz', array_version)\n",
    "\n",
    "# Have a look at some details:\n",
    "print(\"Here's an excerpt of data:\")\n",
    "print(cleaned_data[100:110])\n",
    "cleaned_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading\n",
    "with np.load('roli-block-session-data-diff.npz') as data:\n",
    "    dataset = data['arr_0']\n",
    "print(\"Here's the data shape:\")\n",
    "print(dataset.shape)\n",
    "print(\"Corpus data points between 100 and 120:\")\n",
    "print(dataset[100:120])\n",
    "\n",
    "train_dataset = dataset[:10000]\n",
    "val_dataset = dataset[10000:]\n",
    "\n",
    "print(\"Some statistics about the dataset:\")\n",
    "pd.DataFrame(dataset).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 30\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_UNITS = 128\n",
    "LSTM_LAYERS = 1\n",
    "EPOCHS = 100\n",
    "SEED = 2345  # set random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "OUTPUT_DIMENSION = 4\n",
    "NUMBER_MIXTURES = 3\n",
    "\n",
    "inputs = keras.layers.Input(shape=(SEQ_LEN,OUTPUT_DIMENSION), name='inputs')\n",
    "\n",
    "lstm_inputs = inputs # input for first LSTM layer\n",
    "for i in range(LSTM_LAYERS):\n",
    "    lstm_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm'+str(i), return_sequences=True)(lstm_inputs)\n",
    "    lstm_inputs = lstm_out\n",
    "    \n",
    "#lstm1_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm1', return_sequences=True)(inputs)\n",
    "#lstm2_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm2', return_sequences=True)(lstm1_out)\n",
    "\n",
    "mdn_out = keras.layers.TimeDistributed(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES, name='mdn_outputs'), name='td_mdn')(lstm_out)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=mdn_out)\n",
    "model.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for slicing up data\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_overlapping_format(examples):\n",
    "    \"\"\"Takes sequences of seq_len+1 and returns overlapping\n",
    "    sequences of seq_len.\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:-1])\n",
    "        ys.append(ex[1:])\n",
    "    return (xs,ys)\n",
    "\n",
    "# Prepare training data as X and Y.\n",
    "slices = []\n",
    "#for seq in train_set:\n",
    "slices =  slice_sequence_examples(train_dataset, SEQ_LEN+1)\n",
    "X, y = seq_to_overlapping_format(slices)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)\n",
    "\n",
    "# Prepare validation data as X and Y.\n",
    "slices = []\n",
    "slices +=  slice_sequence_examples(val_dataset, SEQ_LEN+1)\n",
    "Xval, yval = seq_to_overlapping_format(slices)\n",
    "\n",
    "Xval = np.array(Xval)\n",
    "yval = np.array(yval)\n",
    "\n",
    "print(\"Number of validation examples:\")\n",
    "print(\"X:\", Xval.shape)\n",
    "print(\"y:\", yval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "filepath=\"lightpad_mdnrnn-{epoch:02d}.hdf5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks = [keras.callbacks.TerminateOnNaN(), checkpoint]\n",
    "\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, validation_data=(Xval,yval))\n",
    "model.save('lightpad_mdnrnn_model_time_distributed.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame.from_dict(history.history)\n",
    "hist.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decoding Model\n",
    "\n",
    "Let's try it out!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding Model\n",
    "# Same as training model except for dimension and mixtures.\n",
    "\n",
    "# decoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(1,1,OUTPUT_DIMENSION), return_sequences=True, stateful=True))\n",
    "# decoder.add(keras.layers.LSTM(HIDDEN_UNITS, stateful=True))\n",
    "# decoder.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "# decoder.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "# decoder.summary()\n",
    "\n",
    "\n",
    "inputs = keras.layers.Input(shape=(1,OUTPUT_DIMENSION), name='inputs')\n",
    "\n",
    "lstm_inputs = inputs # input for first LSTM layer\n",
    "for i in range(LSTM_LAYERS):\n",
    "    lstm_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm'+str(i), return_sequences=True)(lstm_inputs)\n",
    "    lstm_inputs = lstm_out\n",
    "    \n",
    "#last_output = Lambda(lambda x: x[:,-1,:], output_shape=(1,) + input_shape[2:])(lstm_out)\n",
    "\n",
    "mdn_out = mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES, name='mdn_outputs')(lstm_out)\n",
    "decoder = keras.models.Model(inputs=inputs, outputs=mdn_out)\n",
    "decoder.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer='adam')\n",
    "decoder.summary()\n",
    "\n",
    "decoder.load_weights('lightpad_mdnrnn_model_time_distributed.h5') # load weights independently from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance functions\n",
    "input_colour = 'darkblue'\n",
    "gen_colour = 'firebrick'\n",
    "plt.style.use('seaborn-talk')\n",
    "\n",
    "def perf_df_to_array(perf_df, xylim=1.0, dtlim=5.0):\n",
    "    \"\"\"Converts a dataframe of a performance into array a,b,dt format.\"\"\"\n",
    "    perf_df['dt'] = perf_df.time.diff()\n",
    "    perf_df.dt = perf_df.dt.fillna(0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 5].index, 'dt', dtlim)\n",
    "    perf_df.set_value(perf_df[perf_df.dt < 0].index, 'dt', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.x > 1].index, 'x', xylim)\n",
    "    perf_df.set_value(perf_df[perf_df.x < 0].index, 'x', 0.0)\n",
    "    perf_df.set_value(perf_df[perf_df.y > 1].index, 'y', xylim)\n",
    "    perf_df.set_value(perf_df[perf_df.y < 0].index, 'y', 0.0)\n",
    "    return np.array(perf_df[['x', 'y', 'dt']])\n",
    "\n",
    "def perf_array_to_df(perf_array):\n",
    "    \"\"\"Converts an array of a performance (a,b,dt format) into a dataframe.\"\"\"\n",
    "    perf_array = perf_array.T\n",
    "    perf_df = pd.DataFrame({'dx': perf_array[0], 'dy': perf_array[1], 'dz': perf_array[2], 'dt': perf_array[3]})\n",
    "    perf_df.dt = perf_df.dt.clip(lower=0.0)\n",
    "    perf_df.dx = perf_df.dx.clip(lower=-1.0, upper=1.0)\n",
    "    perf_df.dy = perf_df.dy.clip(lower=-1.0, upper=1.0)\n",
    "    perf_df.dz = perf_df.dz.clip(lower=-1.0, upper=1.0)\n",
    "    perf_df['time'] = perf_df.dt.cumsum()\n",
    "    perf_df['x'] = perf_df.dx.cumsum()\n",
    "    perf_df['y'] = perf_df.dy.cumsum()\n",
    "    perf_df['z'] = perf_df.dz.cumsum()\n",
    "    # As a rule of thumb, could classify taps with dt>0.1 as taps, dt<0.1 as moving touches.\n",
    "    perf_df['moving'] = 1\n",
    "    perf_df.set_value(perf_df[perf_df.dt > 0.1].index, 'moving', 0)\n",
    "    perf_df = perf_df.set_index(['time'])\n",
    "    return perf_df[['x', 'y', 'z', 'moving']]\n",
    "\n",
    "def constrain_perf_df(perf_df):\n",
    "    perf_df.x = perf_df.x.clip(lower=0.0,upper=1.0)\n",
    "    perf_df.y = perf_df.y.clip(lower=0.0,upper=1.0)\n",
    "    perf_df.z = perf_df.z.clip(lower=0.0,upper=1.0)\n",
    "    return(perf_df)\n",
    "\n",
    "\n",
    "def random_touch():\n",
    "    \"\"\"Generate a random tiny performance touch.\"\"\"\n",
    "    return np.array([np.random.rand(), np.random.rand(), 0.01])\n",
    "\n",
    "\n",
    "def constrain_touch(touch):\n",
    "    \"\"\"Constrain touch values from the MDRNN\"\"\"\n",
    "    touch[0] = min(max(touch[0], 0.0), 1.0)  # x in [0,1]\n",
    "    touch[1] = min(max(touch[1], 0.0), 1.0)  # y in [0,1]\n",
    "    touch[2] = max(touch[2], 0.001)  # dt # define minimum time step\n",
    "    return touch\n",
    "\n",
    "def generate_random_tiny_performance(model, n_mixtures, first_touch, time_limit=5.0, steps_limit=1000, temp=1.0):\n",
    "    \"\"\"Generates a tiny performance up to 5 seconds in length.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    previous_touch = first_touch\n",
    "    performance = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1,1,3))\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp)\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        performance.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    return np.array(performance)\n",
    "\n",
    "\n",
    "def condition_and_generate(model, perf, n_mixtures, time_limit=5.0, steps_limit=1000, temp=1.0):\n",
    "    \"\"\"Conditions the network on an existing tiny performance, then generates a new one.\"\"\"\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    # condition\n",
    "    for touch in perf:\n",
    "        params = model.predict(touch.reshape(1,1,3))\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp)\n",
    "    output = [previous_touch.reshape((3,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1,1,3))\n",
    "        previous_touch = mdn.sample_from_output(params[0], 3, n_mixtures, temp=temp)\n",
    "        output_touch = previous_touch.reshape(3,)\n",
    "        output_touch = constrain_touch(output_touch)\n",
    "        output.append(output_touch.reshape((3,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    net_output = np.array(output)\n",
    "    return net_output\n",
    "\n",
    "def divide_performance_into_swipes(perf_df):\n",
    "    \"\"\"Divides a performance into a sequence of swipe dataframes for plotting.\"\"\"\n",
    "    touch_starts = perf_df[perf_df.moving == 0].index\n",
    "    performance_swipes = []\n",
    "    remainder = perf_df\n",
    "    for att in touch_starts:\n",
    "        swipe = remainder.iloc[remainder.index < att]\n",
    "        performance_swipes.append(swipe)\n",
    "        remainder = remainder.iloc[remainder.index >= att]\n",
    "    performance_swipes.append(remainder)\n",
    "    return performance_swipes\n",
    "\n",
    "def plot_2D(perf_df, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    swipes = divide_performance_into_swipes(perf_df)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "def plot_double_2d(perf1, perf2, name=\"foo\", saving=False):\n",
    "    \"\"\"Plot two performances in 2D\"\"\"\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    swipes = divide_performance_into_swipes(perf1)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=input_colour, linewidth=5.0)\n",
    "    swipes = divide_performance_into_swipes(perf2)\n",
    "    for swipe in swipes:\n",
    "        p = plt.plot(swipe.x, swipe.y, 'o-')\n",
    "        plt.setp(p, color=gen_colour, linewidth=5.0)\n",
    "    plt.ylim(1.0,0)\n",
    "    plt.xlim(0,1.0)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    if saving:\n",
    "        plt.savefig(name+\".png\", bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2D(perf_array_to_df(dataset[2000:2050]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a performance\n",
    "\n",
    "decoder.reset_states()\n",
    "\n",
    "#n = np.array([np.random.rand(), np.random.rand(), np.random.rand(), 0.02])\n",
    "n = np.array([0.0, 0.0, 0.0, 0.02])\n",
    "\n",
    "print(n.shape)\n",
    "\n",
    "#print(next)\n",
    "points = []\n",
    "points.append(n)\n",
    "\n",
    "for i in range(30):\n",
    "    params_out = decoder.predict(np.array([[n]]))[0][0]\n",
    "    #print(params_out.shape)\n",
    "    n_out = sample_from_output(params_out, OUTPUT_DIMENSION, NUMBER_MIXTURES, temp=1.0, sig_temp=0.01)\n",
    "    #print(n_out[0].shape)\n",
    "    points.append(n_out[0])\n",
    "    n_in = n_out\n",
    "\n",
    "output = np.array(points)\n",
    "#print(output)\n",
    "print(output.shape)\n",
    "\n",
    "p_df = perf_array_to_df(output)\n",
    "p_df = constrain_perf_df(p_df)\n",
    "print(p_df)\n",
    "plot_2D(p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_mixture_params(params, output_dim, num_mixes):\n",
    "    \"\"\"Splits up an array of mixture parameters into mus, sigmas, and pis\n",
    "    depending on the number of mixtures and output dimension.\"\"\"\n",
    "    mus = params[:num_mixes*output_dim]\n",
    "    sigs = params[num_mixes*output_dim:2*num_mixes*output_dim]\n",
    "    pi_logits = params[-num_mixes:]\n",
    "    return mus, sigs, pi_logits\n",
    "\n",
    "\n",
    "def softmax(w, t=1.0):\n",
    "    \"\"\"Softmax function for a list or numpy array of logits. Also adjusts temperature.\"\"\"\n",
    "    e = np.array(w) / t  # adjust temperature\n",
    "    e -= e.max()  # subtract max to protect from exploding exp values.\n",
    "    e = np.exp(e)\n",
    "    dist = e / np.sum(e)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def sample_from_categorical(dist):\n",
    "    \"\"\"Samples from a categorical model PDF.\"\"\"\n",
    "    r = np.random.rand(1)  # uniform random number in [0,1]\n",
    "    accumulate = 0\n",
    "    for i in range(0, dist.size):\n",
    "        accumulate += dist[i]\n",
    "        if accumulate.any() >= r[0]:\n",
    "            return i\n",
    "    tf.logging.info('Error sampling mixture model.')\n",
    "    return -1\n",
    "\n",
    "\n",
    "def sample_from_output(params, output_dim, num_mixes, temp=1.0, sig_temp=1.0):\n",
    "    \"\"\"Sample from an MDN output with temperature adjustment.\"\"\"\n",
    "    mus = params[:num_mixes*output_dim]\n",
    "    sigs = params[num_mixes*output_dim:2*num_mixes*output_dim]\n",
    "    pis = softmax(params[-num_mixes:], t=temp)\n",
    "    m = sample_from_categorical(pis)\n",
    "    # Alternative way to sample from categorical:\n",
    "    # m = np.random.choice(range(len(pis)), p=pis)\n",
    "    mus_vector = mus[m*output_dim:(m+1)*output_dim]\n",
    "    sig_vector = sigs[m*output_dim:(m+1)*output_dim] * sig_temp  # adjust for temperature\n",
    "    cov_matrix = np.identity(output_dim) * sig_vector\n",
    "    sample = np.random.multivariate_normal(mus_vector, cov_matrix, 1)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    r = np.random.rand(1)  # uniform random number in [0,1]\n",
    "\n",
    "0 >= r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
